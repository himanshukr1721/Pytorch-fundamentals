{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5edb6bb6-a254-4724-a133-18fbe9edb3ee",
   "metadata": {},
   "source": [
    "## 00. Pytorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a82f12-55bb-4413-a278-220b2513e336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec448a-8f55-403a-9411-8d754459fdad",
   "metadata": {},
   "source": [
    "## introduction to Tensors\n",
    "\n",
    "### creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9c1b6d-931d-42ad-b14b-f13ab41fe7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler\n",
    "scaler = torch.tensor(7)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe028d7-9f6a-40b3-9e38-d7b507f0bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b26295-3138-439d-b29d-5d6feece893d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tensor back as Python list\n",
    "scaler.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4506a417-cba9-46f4-a1b4-c1d33f971bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6b4ade-8bfc-44de-a08a-8e7250e4abb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebfec4f-220e-44c8-ab95-7622b9c40b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "231516de-e720-4746-a81f-3cde75cc2240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b45fc0f-e338-4dc0-b760-07b4f76662ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988fca09-2677-450e-8607-f1d0411d5ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006d3760-0ca6-43df-82bc-da31b6d460a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 4, 5],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "\n",
    "TENSOR = torch.tensor([[[1,2,3], [3,4,5], [7,8,9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c31ec30e-701e-450c-8149-7fab90329fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2a0a811-5017-4de2-8fe6-34540f9cd359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb9475-b791-4b6c-afa0-95be4e4824eb",
   "metadata": {},
   "source": [
    "# RANDOM TENSORS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1120e4-423e-4825-a905-3a2b7ace5d80",
   "metadata": {},
   "source": [
    "### RANDOM TENSORS\n",
    "Important bcz the neural networks starts with random number and adjust those random numbers to represent the data in abetter way\n",
    "start with random number -> look at data -> update random numbers -> look at data -> update random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e35fc0-d38b-4fb7-9093-9a36fb00a682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.8108e-02, 7.0395e-01, 2.9901e-01, 4.9660e-01, 9.2187e-01,\n",
       "          4.8362e-01, 8.5645e-01, 3.1235e-01, 9.1324e-01, 9.9485e-01],\n",
       "         [5.8846e-01, 5.0354e-01, 3.7122e-01, 4.6890e-01, 7.9345e-01,\n",
       "          2.0244e-02, 1.0466e-01, 1.3345e-01, 3.4424e-01, 4.9026e-01],\n",
       "         [3.3399e-01, 6.2845e-01, 3.9153e-01, 3.9920e-01, 6.6555e-01,\n",
       "          6.9385e-01, 6.6341e-01, 9.3973e-01, 3.4218e-01, 8.5592e-01],\n",
       "         [1.5221e-01, 9.4183e-01, 3.3948e-01, 3.2084e-01, 9.2623e-01,\n",
       "          6.4355e-01, 2.1988e-01, 2.2727e-04, 5.5211e-01, 2.9493e-01],\n",
       "         [8.0812e-01, 8.8131e-01, 5.3247e-01, 7.6493e-01, 8.1214e-01,\n",
       "          4.9602e-01, 1.2860e-01, 5.4945e-01, 3.3272e-01, 7.4959e-01],\n",
       "         [6.8825e-01, 8.0709e-02, 7.4298e-01, 1.1173e-01, 6.9605e-01,\n",
       "          5.1797e-01, 3.7216e-01, 7.4692e-01, 1.6831e-02, 9.2184e-01],\n",
       "         [7.9347e-02, 8.9241e-01, 3.1197e-01, 5.7203e-01, 2.2305e-01,\n",
       "          5.3379e-02, 7.3268e-01, 2.2914e-01, 8.3893e-01, 5.5194e-01],\n",
       "         [7.5379e-01, 3.5209e-01, 7.2714e-01, 2.5620e-01, 4.0175e-01,\n",
       "          7.1822e-02, 5.2768e-01, 7.2959e-01, 4.2809e-01, 2.5533e-01],\n",
       "         [8.2958e-01, 7.0131e-01, 8.0731e-01, 6.4916e-01, 2.4772e-01,\n",
       "          8.4594e-01, 3.4844e-01, 5.7184e-01, 4.3073e-01, 2.4187e-01],\n",
       "         [7.3361e-01, 3.6839e-01, 1.1879e-01, 5.6873e-01, 4.1421e-01,\n",
       "          7.7889e-01, 4.8015e-01, 6.5149e-01, 5.2467e-01, 7.8984e-01]],\n",
       "\n",
       "        [[7.0285e-01, 5.7000e-01, 8.1210e-01, 8.1643e-01, 6.4933e-01,\n",
       "          9.0885e-01, 7.4249e-01, 7.4766e-01, 3.6987e-01, 4.8723e-01],\n",
       "         [1.5597e-01, 1.9613e-01, 9.9375e-01, 2.6947e-01, 4.3814e-01,\n",
       "          3.8906e-01, 4.4045e-01, 2.1404e-01, 7.9468e-01, 1.1884e-01],\n",
       "         [8.1689e-01, 7.1095e-01, 3.8599e-01, 5.5399e-01, 9.5262e-01,\n",
       "          6.4360e-01, 5.9599e-01, 5.9303e-01, 1.5803e-01, 1.4145e-01],\n",
       "         [8.5374e-01, 8.0851e-01, 4.2790e-01, 9.3183e-01, 7.5973e-01,\n",
       "          5.5852e-02, 4.0493e-01, 4.5889e-01, 3.2693e-01, 7.4977e-01],\n",
       "         [9.0048e-01, 2.8743e-01, 4.4401e-01, 8.3802e-01, 5.8503e-01,\n",
       "          3.7067e-01, 7.4459e-01, 8.2458e-01, 7.5786e-01, 8.7138e-01],\n",
       "         [3.9908e-01, 7.5396e-01, 6.9892e-01, 6.5949e-01, 5.4663e-01,\n",
       "          2.6129e-01, 6.7049e-01, 6.8676e-02, 6.0817e-01, 2.3951e-01],\n",
       "         [6.7846e-01, 6.7201e-01, 6.3100e-01, 1.2602e-01, 6.7613e-01,\n",
       "          3.3252e-01, 6.8953e-01, 2.4296e-01, 5.0748e-01, 1.4082e-01],\n",
       "         [4.5272e-01, 4.9173e-01, 1.6333e-01, 8.9077e-01, 7.9228e-02,\n",
       "          6.8415e-01, 7.4381e-01, 4.1271e-01, 9.2023e-01, 5.5276e-01],\n",
       "         [6.1114e-01, 9.0199e-01, 4.7163e-01, 3.3937e-01, 5.7381e-01,\n",
       "          8.2795e-01, 2.9306e-01, 3.9048e-01, 4.7698e-01, 4.4880e-01],\n",
       "         [5.0304e-01, 6.9812e-01, 1.1669e-01, 9.9376e-02, 7.1659e-01,\n",
       "          2.4293e-01, 1.4564e-01, 4.4137e-01, 7.8783e-01, 1.6933e-01]],\n",
       "\n",
       "        [[8.1080e-02, 1.4230e-01, 1.9098e-01, 1.3049e-01, 9.6705e-01,\n",
       "          7.1989e-01, 2.9728e-01, 2.4126e-01, 5.3031e-02, 2.7258e-01],\n",
       "         [5.4766e-01, 4.2977e-01, 3.7160e-01, 7.3645e-01, 2.2561e-01,\n",
       "          1.3844e-01, 9.5130e-01, 3.8418e-03, 6.9260e-01, 4.7026e-01],\n",
       "         [2.4183e-01, 2.9327e-01, 8.6974e-03, 4.0601e-01, 4.8743e-01,\n",
       "          8.5893e-01, 3.5283e-01, 9.9170e-02, 8.5709e-01, 7.4072e-01],\n",
       "         [4.2962e-01, 3.2319e-01, 2.1946e-01, 1.2946e-01, 4.2981e-01,\n",
       "          1.1102e-01, 1.9257e-01, 9.8497e-04, 6.6169e-01, 5.2125e-01],\n",
       "         [9.2038e-01, 4.3084e-01, 3.2885e-01, 9.1731e-01, 6.8220e-01,\n",
       "          4.1256e-01, 5.5203e-01, 7.5486e-01, 6.3833e-02, 6.9292e-01],\n",
       "         [2.0763e-01, 2.5080e-01, 8.4622e-01, 2.2964e-01, 1.6586e-01,\n",
       "          8.0135e-01, 9.0884e-02, 1.2547e-01, 6.8272e-01, 9.0172e-01],\n",
       "         [2.6878e-01, 5.6712e-01, 2.8740e-02, 8.9924e-01, 1.2865e-01,\n",
       "          9.4555e-01, 6.9997e-01, 1.6048e-01, 8.9787e-01, 6.8400e-01],\n",
       "         [4.8494e-02, 4.3130e-01, 6.0634e-01, 5.3301e-02, 7.5738e-01,\n",
       "          1.1776e-01, 8.6932e-02, 1.4549e-01, 3.2875e-01, 9.3798e-01],\n",
       "         [1.8764e-02, 8.8514e-01, 4.4211e-01, 4.9898e-01, 3.3975e-03,\n",
       "          4.7629e-01, 8.6342e-01, 3.4302e-01, 9.1120e-01, 6.6333e-01],\n",
       "         [9.7557e-01, 2.2221e-01, 6.7816e-01, 6.1521e-01, 3.5790e-01,\n",
       "          3.4957e-01, 5.8732e-01, 4.3417e-01, 9.9309e-01, 6.6618e-01]],\n",
       "\n",
       "        [[2.2539e-01, 4.3167e-01, 4.0649e-01, 3.4662e-01, 6.1376e-01,\n",
       "          6.4158e-01, 1.0496e-01, 3.1850e-01, 4.8706e-01, 9.4247e-01],\n",
       "         [2.7575e-01, 7.3861e-01, 2.7913e-01, 2.2942e-01, 3.6791e-01,\n",
       "          7.4802e-01, 6.3912e-01, 9.5850e-02, 5.3151e-01, 1.1032e-01],\n",
       "         [9.0309e-01, 5.6257e-01, 7.4080e-02, 1.7710e-01, 8.6573e-01,\n",
       "          8.1401e-01, 1.2517e-01, 1.4965e-01, 6.0380e-01, 9.0363e-01],\n",
       "         [1.3677e-01, 2.4931e-01, 9.7678e-01, 3.5391e-03, 8.6691e-01,\n",
       "          1.4796e-01, 3.1471e-01, 9.8048e-01, 2.4442e-01, 4.4568e-01],\n",
       "         [7.3569e-01, 2.6149e-01, 2.9754e-01, 1.9050e-01, 2.1042e-01,\n",
       "          1.3382e-01, 6.8607e-01, 6.8442e-01, 5.7285e-01, 4.9271e-01],\n",
       "         [2.5878e-01, 9.9586e-01, 3.7718e-01, 3.9644e-01, 9.0305e-01,\n",
       "          5.1949e-01, 4.9943e-01, 4.7461e-01, 1.9028e-01, 4.5133e-01],\n",
       "         [6.7145e-01, 9.1952e-01, 4.6130e-01, 4.3919e-01, 7.2151e-01,\n",
       "          7.5084e-01, 5.0252e-01, 8.0791e-01, 4.8319e-01, 6.3556e-01],\n",
       "         [3.0589e-02, 7.9502e-01, 6.9959e-01, 6.7896e-01, 1.4844e-01,\n",
       "          9.4261e-01, 7.0837e-01, 8.9557e-02, 7.6442e-01, 9.3571e-01],\n",
       "         [9.2790e-01, 9.9455e-01, 4.2946e-01, 3.4940e-01, 7.9957e-03,\n",
       "          8.5942e-01, 7.5077e-02, 1.4698e-01, 2.0419e-01, 7.7732e-01],\n",
       "         [9.0810e-01, 3.8530e-01, 6.2549e-01, 1.0737e-01, 9.1532e-01,\n",
       "          1.7421e-01, 3.3551e-01, 9.3547e-01, 8.6485e-01, 8.9397e-01]],\n",
       "\n",
       "        [[4.5181e-02, 1.4559e-01, 5.9983e-01, 6.4193e-01, 8.0939e-01,\n",
       "          4.2149e-01, 7.4458e-02, 8.1523e-01, 7.9618e-01, 6.0740e-01],\n",
       "         [9.8010e-01, 5.3433e-01, 8.2849e-01, 5.5946e-01, 8.2930e-01,\n",
       "          6.8755e-01, 1.1159e-01, 6.7631e-01, 5.6802e-01, 4.0714e-01],\n",
       "         [5.3816e-01, 4.1937e-01, 5.1144e-02, 1.6159e-01, 8.9547e-01,\n",
       "          3.0189e-01, 7.5056e-01, 9.1952e-01, 4.4970e-01, 3.3576e-01],\n",
       "         [6.6999e-01, 5.1608e-01, 5.8079e-01, 5.2831e-01, 1.9283e-01,\n",
       "          2.7331e-01, 6.4294e-02, 7.5880e-01, 5.7334e-03, 8.7503e-01],\n",
       "         [6.6294e-02, 5.9556e-01, 4.6723e-01, 2.3313e-02, 3.5757e-01,\n",
       "          6.8787e-01, 3.3104e-01, 4.6702e-01, 4.6885e-01, 1.2650e-02],\n",
       "         [8.2639e-01, 5.4598e-02, 2.6773e-01, 6.4500e-01, 4.9642e-01,\n",
       "          2.8662e-01, 4.0505e-01, 6.6606e-01, 6.3596e-01, 3.3675e-03],\n",
       "         [6.1707e-01, 7.0368e-01, 9.3647e-01, 9.0105e-01, 9.1825e-01,\n",
       "          8.6773e-02, 5.9524e-01, 2.2389e-02, 2.4004e-01, 6.8450e-01],\n",
       "         [1.7236e-01, 5.1139e-01, 7.0278e-01, 1.5200e-01, 8.5690e-01,\n",
       "          4.2600e-01, 5.2641e-01, 1.0859e-01, 5.8605e-01, 1.1621e-01],\n",
       "         [3.6724e-01, 5.3837e-01, 3.1875e-01, 2.4203e-02, 8.8918e-01,\n",
       "          9.5923e-01, 7.9093e-01, 2.1597e-01, 6.1713e-01, 2.5762e-01],\n",
       "         [7.3171e-01, 7.8388e-01, 5.1367e-01, 1.8876e-01, 5.1484e-01,\n",
       "          2.4109e-01, 5.5700e-01, 3.5843e-01, 8.2695e-01, 9.4091e-03]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor of size (3,4)\n",
    "\n",
    "random_tensor = torch.rand(5,10,10)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba299848-71ae-49a7-b247-b8360cfc6ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim\n",
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d50f84c-b8c3-4f74-8f64-1682f1bcb77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an random tensor with similar to shape of image tensor\n",
    "\n",
    "random_image_tensor = torch.rand(size=(3, 224, 224)) # color channel(RGB), height and width mostly recommended way \n",
    "random_image_tensor.shape, random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c7cc3-8048-43ea-9e47-fc9aa743bb7f",
   "metadata": {},
   "source": [
    "### zeros and ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d59721de-0716-4709-84cc-473ece346c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(5,5))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53c0099b-fc0f-47bd-99b4-8015a3122a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(5,5))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3379d907-4069-46e3-b23b-30990ebef628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffec2e0-650e-4698-8578-b7f94a58450c",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensor like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3917246-b255-4f8f-9a9d-011852f2fdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onetoten = torch.arange(start=1, end=11, step=1)\n",
    "onetoten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8731d60-ed3f-4ed2-aa9d-1643d7e4d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=onetoten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0eee8-d892-43e9-bc22-e46eb92a2a26",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "Note : Tensor datatypes is one of the 3 big errors you will run into pytorch and deep learning\n",
    "1. tensors not right datatype\n",
    "2. tensors not right shape\n",
    "3. tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2840fda-7c54-43e4-8ae9-78ff6cadbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None,\n",
    "                                                device=None,\n",
    "                                                requires_grad=False)\n",
    "print(float_32_tensor)\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f743b8f-53b6-4a37-9e75-9bc7fc35d6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16 = float_32_tensor.type(torch.float16)\n",
    "float_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7197394d-c8db-4b2e-be58-53ea1dbf0478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16 * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "702a99be-3903-49ad-8573-15e9a3879a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int64)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec8edbd3-fe4c-4e4e-92bf-143ce5169508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16 * int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639ed38-d328-4fe6-9785-0bd7c4f1e182",
   "metadata": {},
   "source": [
    "### GEtting informations from Tensors\n",
    "1. tensors not right datatype - to do get datatype from tensor can use 'tensor.dtype'\n",
    "2. tensors not right shape - to get shape from a tensor can use 'tensor.shape'\n",
    "3. tensors not on the right device - to get device from tensor can use 'tensor.device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2d891af-4f71-439f-b4a4-7b2d88a53b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1978, 0.3647, 0.2954, 0.5635],\n",
       "        [0.7534, 0.9429, 0.0117, 0.7480],\n",
       "        [0.2314, 0.4019, 0.0303, 0.0371]], dtype=torch.float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4, dtype=torch.float16,\n",
    "                              device=None,\n",
    "                              requires_grad=False)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ae64864-5937-4d4b-8ced-a16849a123ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1978, 0.3647, 0.2954, 0.5635],\n",
      "        [0.7534, 0.9429, 0.0117, 0.7480],\n",
      "        [0.2314, 0.4019, 0.0303, 0.0371]], dtype=torch.float16)\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float16\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3165e0-67d1-4849-9f81-24f05487d86c",
   "metadata": {},
   "source": [
    "### Manupulating Tensors (Tensor Operations)\n",
    "Tensor operation include:\n",
    "Addition\n",
    "Substraction\n",
    "Multiplication (element-wise)\n",
    "Division\n",
    "Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de152a31-68e8-4933-b4ee-c4fac6d6d588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00d22be4-ea9a-4663-a60a-d2c382f3d6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23, 46, 69])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try out pyroch inbuit functions\n",
    "torch.mul(tensor, 23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11698c2c-401d-412d-9bd4-f4fe503d5f19",
   "metadata": {},
   "source": [
    "### MAtrix MUltiplicaation'\n",
    "two main ways of matrix multiplication \n",
    "1. element wise \n",
    "2. matrix mul...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1343f72-b8ba-4826-945d-9a789a35f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])  *  tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "#elemt wise \n",
    "print(tensor, \" * \", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe4df47f-ebdb-409b-818d-082b0fc98e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAtric MUl\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d596a0-a0d0-47e4-a5f2-1c4e178fef1f",
   "metadata": {},
   "source": [
    "\n",
    "One of the most common errors in deep learning (shape errors)\n",
    "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47c3b2ed-6dd3-470e-aa85-a304955c7127",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ccaa35-0203-4091-bdb5-9931aeb4edf3",
   "metadata": {},
   "source": [
    "TO fix our tensor shape issue we transpose it \n",
    "transpose switches the axes or dimension of a given tensor\n",
    "\n",
    "tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1753de31-26a3-4401-9c23-e283183dad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7., 10.],\n",
       "        [ 8., 11.],\n",
       "        [ 9., 12.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a74c6364-06ac-4a9d-a131-d818567a1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.,  8.,  9.],\n",
       "        [10., 11., 12.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82a6f214-3c04-42a0-98f0-db6e07d6cca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "output = torch.matmul(tensor_A, tensor_B.T) # we can by transposing it into requird shape\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "153b5e93-0b35-491d-a34a-72200e63f328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ca324-4222-4cc6-8c66-6682b8cc964a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
